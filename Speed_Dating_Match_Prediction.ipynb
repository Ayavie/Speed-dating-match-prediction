{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayavie/Speed-dating-match-prediction/blob/main/Speed_Dating_Match_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLgy0NqJZnYk"
      },
      "source": [
        "#✔️ Problem Formulation:\n",
        "Define the problem. What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?\n",
        "\n",
        "The objective of this problem to find whether 2 people matches in a certain speed dating program.\n",
        "\n",
        "The input we have are the profile of each person who joined this program of some personal information about life style, education and job, preferences and so on. \n",
        "\n",
        "The output whether 2 people matches or not at the end of the program.\n",
        "\n",
        "The challenge is to find the best way to deal with the missing values as they are alot.\n",
        "\n",
        "The impact will be setting 2 people who are predicted to be matching together by the model and have higher success rate for the dating sessions program if the model has high accuracy.\n",
        "\n",
        "I think the ideal solution could be a model predicting more than 70% evaluation metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD4GUbTHz9FP"
      },
      "source": [
        "#Importing the libraries and investigating the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDdoR1_s_n8r"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost.sklearn import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8toznq6LAcoX"
      },
      "outputs": [],
      "source": [
        "#Reading data files\n",
        "\n",
        "#Training data\n",
        "#Initialize main dataframe \n",
        "df_main=pd.read_csv('train.csv')\n",
        "\n",
        "#Make a copy of the main dataframe for usage\n",
        "df=df_main.copy()\n",
        "\n",
        "df2=df_main.copy()\n",
        "#Testing data\n",
        "df_test=pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4M1oSLerX8Z",
        "outputId": "b1879c62-f54c-40cf-f0bc-c022e8f00e06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2469, 191)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Test dataframe size\n",
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTRObZkuBtVn",
        "outputId": "d7f0223f-2a26-4d0e-dccb-0bcdd21ade90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5909, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Training dataframe size\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "26l2qS18A7KU",
        "outputId": "0882545c-10ac-45d0-8958-78995b2fcad0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-228d6530-f5d0-44e2-9bb0-c95c8d8a21c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>idg</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condtn</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wave</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>round</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sinc5_3</th>\n",
              "      <td>4496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intel5_3</th>\n",
              "      <td>4496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fun5_3</th>\n",
              "      <td>4496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amb5_3</th>\n",
              "      <td>4496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-228d6530-f5d0-44e2-9bb0-c95c8d8a21c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-228d6530-f5d0-44e2-9bb0-c95c8d8a21c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-228d6530-f5d0-44e2-9bb0-c95c8d8a21c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0\n",
              "gender       0\n",
              "idg          0\n",
              "condtn       0\n",
              "wave         0\n",
              "round        0\n",
              "...        ...\n",
              "sinc5_3   4496\n",
              "intel5_3  4496\n",
              "fun5_3    4496\n",
              "amb5_3    4496\n",
              "id           0\n",
              "\n",
              "[192 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Checking sum of missing values in each column and putting them into a dataframe to read them\n",
        "\n",
        "df_null=pd.DataFrame(df.isnull().sum())\n",
        "\n",
        "df_null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rucCa1aOBcLG",
        "outputId": "3b8ba9e0-1574-4eab-eea8-088135c59572"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender         0\n",
              "idg            0\n",
              "condtn         0\n",
              "wave           0\n",
              "round          0\n",
              "            ... \n",
              "sinc5_3     4496\n",
              "intel5_3    4496\n",
              "fun5_3      4496\n",
              "amb5_3      4496\n",
              "id             0\n",
              "Length: 192, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#summtion of nulls in each column\n",
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEukJC-wxIoI",
        "outputId": "0a735ace-1b3b-4329-8139-3afbd9cf7013"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender      5909\n",
              "idg         5909\n",
              "condtn      5909\n",
              "wave        5909\n",
              "round       5909\n",
              "            ... \n",
              "sinc5_3     5909\n",
              "intel5_3    5909\n",
              "fun5_3      5909\n",
              "amb5_3      5909\n",
              "id          5909\n",
              "Length: 192, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.isnull().count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "r2EkMGg5C6iD",
        "outputId": "d0b2511f-5d31-49ee-98f6-2b9d9de5d4b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1ca7124-1184-43f1-95f2-4205da728c84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_in_3</th>\n",
              "      <th>numdat_3</th>\n",
              "      <th>expnum</th>\n",
              "      <th>amb7_2</th>\n",
              "      <th>sinc7_2</th>\n",
              "      <th>shar7_2</th>\n",
              "      <th>fun7_2</th>\n",
              "      <th>intel7_2</th>\n",
              "      <th>attr7_2</th>\n",
              "      <th>attr7_3</th>\n",
              "      <th>...</th>\n",
              "      <th>idg</th>\n",
              "      <th>samerace</th>\n",
              "      <th>match</th>\n",
              "      <th>partner</th>\n",
              "      <th>order</th>\n",
              "      <th>position</th>\n",
              "      <th>round</th>\n",
              "      <th>wave</th>\n",
              "      <th>condtn</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>92.215265</td>\n",
              "      <td>82.061262</td>\n",
              "      <td>78.304282</td>\n",
              "      <td>76.476561</td>\n",
              "      <td>76.476561</td>\n",
              "      <td>76.239634</td>\n",
              "      <td>76.121171</td>\n",
              "      <td>76.121171</td>\n",
              "      <td>76.121171</td>\n",
              "      <td>76.087324</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 192 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1ca7124-1184-43f1-95f2-4205da728c84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1ca7124-1184-43f1-95f2-4205da728c84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1ca7124-1184-43f1-95f2-4205da728c84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    num_in_3   numdat_3     expnum     amb7_2    sinc7_2    shar7_2  \\\n",
              "0  92.215265  82.061262  78.304282  76.476561  76.476561  76.239634   \n",
              "\n",
              "      fun7_2   intel7_2    attr7_2    attr7_3  ...  idg  samerace  match  \\\n",
              "0  76.121171  76.121171  76.121171  76.087324  ...  0.0       0.0    0.0   \n",
              "\n",
              "   partner  order  position  round  wave  condtn   id  \n",
              "0      0.0    0.0       0.0    0.0   0.0     0.0  0.0  \n",
              "\n",
              "[1 rows x 192 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Get null percentage in each column and convert it to dataframe \n",
        "null_percent = pd.DataFrame(((df.isnull().sum()/df.isnull().count()).sort_values(ascending=False))*100).T\n",
        "null_percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxd9ahk8rP6q",
        "outputId": "a1929667-e541-41af-ec81-e11ec3aeb008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    92.215265\n",
              "Name: num_in_3, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#df[colname]\n",
        "null_percent[null_percent.columns[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TVIF5liurBr",
        "outputId": "13209695-a66e-4218-8f3d-140599be1f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    True\n",
            "Name: numdat_3, dtype: bool\n"
          ]
        }
      ],
      "source": [
        "print(null_percent[null_percent.columns[1]]>=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42wlJR4ri1bQ",
        "outputId": "4ccbfaa6-fc1f-4c45-d8e2-f41f277a30b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['num_in_3',\n",
              " 'numdat_3',\n",
              " 'expnum',\n",
              " 'amb7_2',\n",
              " 'sinc7_2',\n",
              " 'shar7_2',\n",
              " 'fun7_2',\n",
              " 'intel7_2',\n",
              " 'attr7_2',\n",
              " 'attr7_3',\n",
              " 'sinc7_3',\n",
              " 'intel7_3',\n",
              " 'fun7_3',\n",
              " 'amb7_3',\n",
              " 'shar7_3',\n",
              " 'shar2_3',\n",
              " 'attr5_3',\n",
              " 'sinc5_3',\n",
              " 'intel5_3',\n",
              " 'fun5_3',\n",
              " 'amb5_3',\n",
              " 'shar4_3',\n",
              " 'fun4_3',\n",
              " 'intel4_3',\n",
              " 'sinc4_3',\n",
              " 'attr4_3',\n",
              " 'attr2_3',\n",
              " 'sinc2_3',\n",
              " 'intel2_3',\n",
              " 'fun2_3',\n",
              " 'amb2_3',\n",
              " 'amb4_3',\n",
              " 'mn_sat']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Initialize a list and append column names that contain nulls more than 60% of its size \n",
        "null_cols=[]\n",
        "for i in range(null_percent.shape[1]):\n",
        "  if (null_percent[null_percent.columns[i]]>=60).any():\n",
        "     colname=null_percent.columns[i]\n",
        "     null_cols.append(colname)\n",
        "\n",
        "null_cols\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BPo9Itv0ete"
      },
      "source": [
        "#Assigning dependent and independent variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9b3Cn5dTw8e",
        "outputId": "ac208533-2217-47fd-cbbb-429ebeea5d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape (5909, 191) (5909,)\n",
            "y_test 3489    0\n",
            "4909    0\n",
            "1425    0\n",
            "4743    0\n",
            "439     0\n",
            "       ..\n",
            "5333    0\n",
            "4310    0\n",
            "653     0\n",
            "429     0\n",
            "1773    1\n",
            "Name: match, Length: 1182, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Assigning dependent and independent variables\n",
        "y = df['match'] # lower case for vector\n",
        "X = df.drop('match', axis=1) # upper case for matrix\n",
        "print('original shape', X.shape, y.shape)\n",
        "\n",
        "# now we can split the data into train and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print('y_test', y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDIN_v4L0t61"
      },
      "source": [
        "# Extracting numeric features and categorical features names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJTq2tAAYUjU",
        "outputId": "021ff960-c503-4d0e-ec24-3f5be249b557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numeric features: ['gender', 'idg', 'condtn', 'wave', 'round', 'position', 'positin1', 'order', 'partner', 'pid', 'int_corr', 'samerace', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'expnum', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1', 'fun3_1', 'intel3_1', 'amb3_1', 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'prob', 'met', 'match_es', 'attr1_s', 'sinc1_s', 'intel1_s', 'fun1_s', 'amb1_s', 'shar1_s', 'attr3_s', 'sinc3_s', 'intel3_s', 'fun3_s', 'amb3_s', 'satis_2', 'length', 'numdat_2', 'attr7_2', 'sinc7_2', 'intel7_2', 'fun7_2', 'amb7_2', 'shar7_2', 'attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2', 'attr4_2', 'sinc4_2', 'intel4_2', 'fun4_2', 'amb4_2', 'shar4_2', 'attr2_2', 'sinc2_2', 'intel2_2', 'fun2_2', 'amb2_2', 'shar2_2', 'attr3_2', 'sinc3_2', 'intel3_2', 'fun3_2', 'amb3_2', 'attr5_2', 'sinc5_2', 'intel5_2', 'fun5_2', 'amb5_2', 'you_call', 'them_cal', 'date_3', 'numdat_3', 'num_in_3', 'attr1_3', 'sinc1_3', 'intel1_3', 'fun1_3', 'amb1_3', 'shar1_3', 'attr7_3', 'sinc7_3', 'intel7_3', 'fun7_3', 'amb7_3', 'shar7_3', 'attr4_3', 'sinc4_3', 'intel4_3', 'fun4_3', 'amb4_3', 'shar4_3', 'attr2_3', 'sinc2_3', 'intel2_3', 'fun2_3', 'amb2_3', 'shar2_3', 'attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3', 'attr5_3', 'sinc5_3', 'intel5_3', 'fun5_3', 'amb5_3', 'id']\n",
            "categorical features: ['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income', 'career']\n"
          ]
        }
      ],
      "source": [
        "# for later use\n",
        "\n",
        "# numeric features can be selected by: (based on the df2.info() output )\n",
        "features_numeric = list(X_train.select_dtypes(include=['float64', 'int64']))\n",
        "\n",
        "# categorical features can be selected by: (based on the df2.info() output )\n",
        "features_categorical = list(X_train.select_dtypes(include=['object']))\n",
        "\n",
        "print('numeric features:', features_numeric)\n",
        "print('categorical features:', features_categorical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XobJ5eBr1yKm"
      },
      "source": [
        "#Strategy used throughout the whole code\n",
        "1) Defining a function that creates a pipeline that determines preprocessing and classifier\n",
        "\n",
        "\n",
        "2) Try 2 different classifiers ( RandomForest and XGBoost Classifier )\n",
        "\n",
        "3) Using the best one with its default parameters \n",
        "\n",
        "4) Applying 3 different tuning techniques on it\n",
        "\n",
        "    1. Grid search \n",
        "\n",
        "    2. Random search \n",
        "\n",
        "    3. Bayesian search \n",
        "\n",
        "5) Try different preprocessing (dropping features and using different imputers)\n",
        "\n",
        "6) The evaluation metric used is AUROC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNg6xlha1Ijf"
      },
      "source": [
        "##First pipeline function initialization\n",
        "In this pipeline we will:\n",
        "\n",
        "1. Use all features.\n",
        "2. Numeric data: \n",
        " * Fill numeric features than contain nans with the mean.\n",
        " * Standardize numeric data.\n",
        "3. Categorical features:\n",
        "  * Fill categorical features that contain nans with \"missing_value\".\n",
        "  * One-Hot-Encode them.\n",
        "4. Use RandomForest Classifier.\n",
        "5. XGBoost Classifier.\n",
        "\n",
        "**Thoughts:** Not much as this is the a base trial for the model. All I can expect is that there won't be high accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to drop columns determined before plus new ones which are considered useless or redundant \n",
        "def drop_features(df):\n",
        "  df.drop(columns=null_cols+['id','from','career'],inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "C3HwhuQRxfwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scxMLYXMb-XF"
      },
      "outputs": [],
      "source": [
        "#Defining function for the whole pipeline used for the model (Preprocessing and model initialization)\n",
        "def first_pipeline(df,classifier,imputer,all_features=True):\n",
        "  \n",
        "  def drop_features(df):\n",
        "    df=df.drop(columns=null_cols,axis=1,inplace=True)\n",
        "    return df \n",
        "\n",
        "  #Fixing random seed for reproducibility\n",
        "  np.random.seed(0)\n",
        "   \n",
        "\n",
        "  # Define a pipe line for numeric feature preprocessing\n",
        "  # We gave them a name so we can set their hyperparameters\n",
        "  transformer_numeric = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', imputer),\n",
        "        ('scaler', StandardScaler())]\n",
        ")\n",
        "  \n",
        "\n",
        "  # Define a pipe line for categorical feature preprocessing\n",
        "  # We gave them a name so we can set their hyperparameters\n",
        "  # Filling missing values of categorical features with '0'\n",
        "  transformer_categorical = Pipeline(\n",
        "      steps=[\n",
        "          ('imputer', SimpleImputer(strategy='constant')),\n",
        "          ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "      ]\n",
        "  )\n",
        "  print('done transformer_categorical ')\n",
        "  # define the preprocessor \n",
        "  # we gave them a name so we can set their hyperparameters\n",
        "  # we also specify what are the categorical \n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          ('num', transformer_numeric, features_numeric),\n",
        "          ('cat', transformer_categorical, features_categorical)\n",
        "      ]\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  # combine the preprocessor with the model as a full tunable pipeline\n",
        "  # we gave them a name so we can set their hyperparameters\n",
        "  if (all_features==True):\n",
        "\n",
        "    full_pipline = Pipeline(\n",
        "        steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('my_classifier', \n",
        "            classifier,\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "  else:\n",
        "\n",
        "\n",
        "\n",
        "        full_pipline = Pipeline(\n",
        "        steps=[\n",
        "            ('dropping_features',drop_features(df)),\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('my_classifier', \n",
        "            classifier,\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "       \n",
        "\n",
        "\n",
        "  return full_pipline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdbJGGvwggd_"
      },
      "source": [
        "##**Next:** RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOVIBbD5ZFDa",
        "outputId": "c240973d-bd6c-4dcf-98a6-52db73506626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done transformer_categorical \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Calling pipeline function and assign it to model variable\n",
        "model=first_pipeline(df,RandomForestClassifier(),SimpleImputer()).fit(X_train, y_train)\n",
        "model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwhK1NUe7ZWr"
      },
      "outputs": [],
      "source": [
        "#Make submission sample using predictions\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['match'] = model.predict_proba(df_test)[:,1]\n",
        "\n",
        "submission.to_csv('submission_RF.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP2PLrOxF1Ye"
      },
      "source": [
        "### **Observation 1** : Random Forest\n",
        "Got low testing accuracy of value $0.82959 !$\n",
        "\n",
        "This means underfitting but not bad for starters with primary model only!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP1Qu0UojEgg"
      },
      "source": [
        "## **Next**: XGBoost\n",
        "We'll try to use different optimizer which is XGBoost classifier with the same pipeline used.\n",
        "\n",
        "### **Expectation**:\n",
        " We can not expect whether XGBoost will perform better using the same pipeline so let's find out the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRPBTCPcfVVm",
        "outputId": "b6b945dd-b574-44e6-990e-9c09bd609e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done transformer_categorical \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Calling pipeline function and assign it to model variable\n",
        "model=first_pipeline(df,XGBClassifier(),SimpleImputer()).fit(X_train, y_train)\n",
        "model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwtPhTG_fVVv"
      },
      "outputs": [],
      "source": [
        "#Make submission sample using predictions\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['match'] = model.predict_proba(df_test)[:,1]\n",
        "\n",
        "submission.to_csv('submission_xgb.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SVKtw3LDBDS"
      },
      "source": [
        "### **Observation 2** : XGBoost \n",
        "\n",
        "\n",
        "XGBClassifier got $0.87092$ testing accuracy which is much higher than RandomForestClassifier!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID18sjeWkRxQ"
      },
      "source": [
        "## **Next**: 3 different tuning techniques\n",
        "\n",
        "We'll use 3 different tuning techniques (GridSearch, RandomSearch, BayesianSearch) on XGBoostClassifier and try to get better accuracy.\n",
        "\n",
        "### **Expectations** :\n",
        "\n",
        "I can expect that the model's test accuracy will increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fpNahWSkjcI"
      },
      "source": [
        "###  **GridSearch with XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOm_S5D9q5RF",
        "outputId": "d9ab3523-ec36-46e6-ac8c-0081d081eb2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 70 candidates, totalling 280 fits\n",
            "best score 0.8598146189936264\n",
            "best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 40, 'preprocessor__num__imputer__strategy': 'median'}\n"
          ]
        }
      ],
      "source": [
        "# here we specify the search space\n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'my_classifier__n_estimators': [10,15,20,25,30,35, 40],  \n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    'my_classifier__max_depth':[10,15, 20,25, 30]       \n",
        "}\n",
        "\n",
        "# cv=2 means two-fold cross-validation\n",
        "# n_jobs means the cucurrent number of jobs\n",
        "# (on colab since we only have two cpu cores, we set it to 2)\n",
        "grid_search = GridSearchCV(\n",
        "    model, param_grid, cv=4, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QyqpujMsaTx"
      },
      "outputs": [],
      "source": [
        "#Predicting testdata using gridseach with xgboost\n",
        "grid_search.predict(X_test)\n",
        "\n",
        "#Make submission sample using predictions\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['match'] = grid_search.predict_proba(df_test)[:,1]\n",
        "\n",
        "submission.to_csv('submission_xgb_GS.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG7lYNyNvCVJ"
      },
      "source": [
        "GridSearch with XGBoost got testing accuracy score: **0.86287**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtBnXrStk_gg"
      },
      "source": [
        "###  **RandomSearch with XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKqg9WoEao4a",
        "outputId": "bdb185cd-d667-4635-bdca-9380711e228e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "best score 0.8557845752521942\n",
            "best score {'preprocessor__num__imputer__strategy': 'median', 'my_classifier__n_estimators': 40, 'my_classifier__max_depth': 30}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "   model, param_grid, cv=4, verbose=1, n_jobs=2, \n",
        "    # number of random trials\n",
        "    n_iter=10,\n",
        "    scoring='roc_auc',\n",
        "    random_state=0)\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(random_search.best_score_))\n",
        "print('best score {}'.format(random_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5144MAcUtFLM"
      },
      "outputs": [],
      "source": [
        "#Predicting testdata using gridseach with xgboost\n",
        "random_search.predict(X_test)\n",
        "\n",
        "#Make submission sample using predictions\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['match'] = random_search.predict_proba(df_test)[:,1]\n",
        "\n",
        "submission.to_csv('submission_xgb_RS.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFf3qfNSu1ca"
      },
      "source": [
        "RandomSearch with XGBoost got testing accuracy score: **0.85842**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAT3Ta_ilDbw"
      },
      "source": [
        "###  **Bayesian Search with XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA9BjktuawAO",
        "outputId": "2653c11b-a39a-4562-9d79-043942f887bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 100 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F_nFAkzav70",
        "outputId": "f46d458c-d3d4-4d66-e531-c7561746d9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
            "best score 0.8569260235085413\n",
            "best score OrderedDict([('my_classifier__max_depth', 10), ('my_classifier__n_estimators', 35), ('preprocessor__num__imputer__strategy', 'median')])\n"
          ]
        }
      ],
      "source": [
        "#Importing BayesSearch and fitting it with our model of XGBoost\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "\n",
        "model, param_grid, cv=4, verbose=1, n_jobs=2, \n",
        "    # number of random trials\n",
        "    n_iter=10,\n",
        "    scoring='roc_auc',\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search.best_score_))\n",
        "print('best score {}'.format(bayes_search.best_params_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh57FqIAav5E"
      },
      "outputs": [],
      "source": [
        "#Predicting testdata using gridseach with xgboost\n",
        "bayes_search.predict(X_test)\n",
        "\n",
        "#Make submission sample using predictions\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['match'] = bayes_search.predict_proba(df_test)[:,1]\n",
        "\n",
        "submission.to_csv('submission_xgb_BS.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjKSzO-zwSCi"
      },
      "source": [
        "BayesSearch with XGBoost got testing accuracy score: **0.86076**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observation 3:**\n",
        "\n",
        "\n",
        "\n",
        "* GridSearch with XGBoost got training accuracy **0.85981** testing accuracy score: **0.86287**\n",
        "\n",
        "* RandomSearch with XGBoost got training accuracy **0.85578** testing accuracy score: **0.85842**\n",
        "\n",
        "\n",
        "* BayesSearch with XGBoost got training accuracy **0.85692** testing accuracy score: **0.86076**\n",
        "\n",
        "\n",
        "> GridSearch got the highest score among the three of them but so far XGB classifier without gridsearch got higher accuracy of score $0.87092!!$"
      ],
      "metadata": {
        "id": "Ngxc8BJmA9eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Next We'll use different preprocessing technique\n",
        "We'll drop columns that contain more than 60% null values with XGBoost and let's see how would that affect model accuracy!"
      ],
      "metadata": {
        "id": "TNJBTFvpoDAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop_features(df2)"
      ],
      "metadata": {
        "id": "W0DRXvLywK7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cdbe7c-2222-481f-81a2-dfc86d5587a0",
        "id": "w6Zql_b-ozYY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done transformer_categorical \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Calling pipeline function and assign it to model variable\n",
        "model=first_pipeline(df2,XGBClassifier(),SimpleImputer(),all_features=False)\n",
        "model.fit(X_train, y_train)\n",
        "model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I74OSYZozYe"
      },
      "outputs": [],
      "source": [
        "#Make submission sample using predictions\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['match'] = model.predict_proba(df_test)[:,1]\n",
        "\n",
        "submission.to_csv('submission_xgb2.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Observation 1** : Trial 2  \n",
        "XGBClassifier got $0.87517$ testing accuracy which is slightly higher than last time with all features which got $0.8709$\n"
      ],
      "metadata": {
        "id": "fb0uCrLCxxia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Next** :\n",
        "We'll use the previous model with iterative imputer instead of simple imputer\n",
        "\n",
        "### **Expectation** :\n",
        " Higher accuracy as it estimates each feature from all the others."
      ],
      "metadata": {
        "id": "VCYT_8h4276i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Terative Imputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer"
      ],
      "metadata": {
        "id": "AZrX9RP-4wI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220912c3-31d7-407e-d62e-37d4d6ae1c16",
        "id": "b-EZwiKR4OsU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done transformer_categorical \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Calling pipeline function and assign it to model variable\n",
        "model=first_pipeline(df2,XGBClassifier(),IterativeImputer(random_state=0))\n",
        "model.fit(X_train, y_train)\n",
        "model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0Rm8yWg4OsV"
      },
      "outputs": [],
      "source": [
        "#Make submission sample using predictions\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['match'] = model.predict_proba(df_test)[:,1]\n",
        "\n",
        "submission.to_csv('submission_xgb_itimp.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Observation 2** : Trial 2\n",
        "And I guess I my expectation went wrong.\n",
        "Using Iterative imputer got testing accuracy of value $0.87477$ which is slightly worse than using simple imputer which got testing accuracy $0.87517$\n",
        "We can conclude that maybe depending on all features is not reliable and not all of them should contribute in predicting others which contain null values.\n"
      ],
      "metadata": {
        "id": "FQQ7Su4f5gSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Observation** : \n",
        "Best model used was the one with feature selection(dropped some features) with XGB Classifier and Simple Imputer.\n",
        "\n",
        " (With header: $Observation 1: Trial 2$ ) "
      ],
      "metadata": {
        "id": "2_n73Aws7eqt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgvCCubMZzNS"
      },
      "source": [
        "#✔️ Answer the questions below (briefly):\n",
        "\n",
        "\n",
        "\n",
        "🌈 1. Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?\n",
        "\n",
        "> Answer: Linear Regression is not suitable for classification for 2 reasons. \n",
        "1. Linear Regression deals with continuous values whereas classification problems deals with discrete values.\n",
        "2. The shift problem in threshold value when new data points are added, the line shifts to fit most of the data.\n",
        "\n",
        "> On the other hand, Logistic Regression deals with discrete values unlike Linear Regression and it also maintains the value of the threshold even when new data points are added.\n",
        "\n",
        "> Linear regression is the same as MLP with no activation function which is considered a closed form solution where you can compute the output directly and efficiently as well but once you add activation function to MLP it will be iterative solution in which the algorithm need to go through steps to compute the output and also computations to improve with each step and that would be a lot slower than direct solution.\n",
        "\n",
        "> Another different is that in MLP with hidden layers and activation functions, the model becomes much more powerful and also has the ability to tune as when you increase number of hidden layers the model will be able to extract more features, get better accuracy and less error but in simple neural network or linear regression the model can only model linear function which are almost does not exist in real life senarios. \n",
        "\n",
        "🌈What's a decision tree and how it is different to a logistic regression model?\n",
        "\n",
        "> Answer: Decision tree is an algorithm used for both regression and classification used to split dataset into smaller subsets until each leaf contain values belong to one only feature or category so it can not be split anymore.\n",
        "Logistic regression is an algorithm used  for modeling the probability of a discrete outcome given an input variable. It is used in binary classification.\n",
        "\n",
        "> Decision Trees bisect the space into smaller and smaller regions, while Logistic Regression fits a single line to divide the space exactly into two. For higher-dimensional data, these lines would generalize to planes and hyperplanes. A single linear boundary can sometimes be limiting for Logistic Regression.\n",
        "\n",
        "\n",
        "🌈What's the difference between grid search and random search?\n",
        "\n",
        "> Answer: GridSearch tries all combination of hyperparaeters range specfied to it. It allow you to know the best combination among them and best score. \n",
        "On the other hand, random search is tries random combinations of hyperparameters used in the search space and it allow you to know the best combination among the only trials it made and its best score.\n",
        "\n",
        "\n",
        "🌈What's the difference between bayesian search and random search?\n",
        "\n",
        "\n",
        ">Answer: Random search is tries random combinations of hyperparameters used in the search space and it allow you to know the best combination among the only trials it made and its best score. while Bayesian optimization is a sequential model-based optimization (SMBO) algorithm that uses the results from the previous iteration to decide the next hyperparameter value candidates.\n",
        "So instead of blindly searching the hyperparameter space (like in grid search and random search), this method advocates the usage of intelligence to pick the next set of hyperparameters which will improve the model performance. We iteratively repeat this process until we converge to an optimum.\n",
        "\n",
        "\n",
        "**References:**\n",
        "\n",
        "https://medium.com/analytics-vidhya/why-linear-regression-is-not-suitable-for-classification-cd724dd61cb8\n",
        "\n",
        "https://blog.bigml.com/2016/09/28/logistic-regression-versus-decision-trees/ \n",
        "\n",
        "https://medium.com/analytics-vidhya/comparison-of-hyperparameter-tuning-algorithms-grid-search-random-search-bayesian-optimization-5326aaef1bd1\n",
        "\n",
        "\n",
        "https://cs.stackexchange.com/questions/28597/difference-between-multilayer-perceptron-and-linear-regression"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nP2PLrOxF1Ye"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMSxxPdHU6TMbrgal6igmMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}